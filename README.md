# MagLevNet
Neural Network Model for Magnetic Levitation System

References:
-----------
[ **BeHaDe2010** ] Beale, M. H., M. T. Hagan, H. B. Demuth ( 2010 ). Neural Network Toolbox 7: User's guide, The Mathworks Inc.

[ **Ha2014** ] Hagan M. ( 2014 ). Neural Network Design.

[ **HaDeJe2002** ] Hagan, M. T., H. B. Demuth and O. D. Jesus ( 2002 ). An introduction to use of neural networks in control systems. International Journal of Robust and Nonlinear Control, 12( 11 ), 959-985.

Code
----
The problem is discretized into three stages:
> 1. Obtaining input-output data from the system
> 2. Training a Neural Net ( Multi-Layer Perceptron ) using this data
> 3. Check performance of Neural Net

## Magnetic Levitation System
The system consists of a vertically-only movable levitating magnet whose position is controlled by current flowing through an electromagnet. This is modelled as a second-order nonlinear system [ **BeHaDe2010** ].
### Obtaining input-output data
To obtain a good data-based model, all frequencies and amplitudes within the desired operating range of this nonlinear dynamical system needs to be excited. An **A**mplitude-modulated **P**seudo **R**andom **B**inary **S**equence, generated by `GenSkyline` function in [ `Files/ExcitationSignal.m` ]( https://github.com/JohnDoe2576/MagLevNet/blob/master/Files/ExcitationSignal.m ), helps design such a signal. This excitation signal is supplied to armature coil of the electromagnet, and the corresponding position ( vertical ) of the levitating magnet is simulated using MATLAB `ode45` solver in function [ `SimMagLev` ]( https://github.com/JohnDoe2576/MagLevNet/blob/master/SimMagLev.m ) to obtain the input-output sequence. The figure below shows the an example of input APRBS sequence ( U ) and corresponding system output ( Y ).

![]( https://github.com/JohnDoe2576/MagLevNet/blob/master/DataStore/Fig/MagLevTestingData1.png )

### Setting-up a Neural Network
A Dynamical Neural Net ( Multi-Layer Perceptron ) is chosen in such a way that, the current output of system is a function of previous inputs to the system and previous outputs from the system. The network is then constructed with the following parameters:
> - Number of Hidden Layers: 1
> - Number of neurons in Hidden Layer: 10
> - Number of delayed inputs: 8
> - Number of delayed outputs: 8

The well-trained network should be general enough ( i.e.; should not overfit ) to accuratley predict any behaviour outside of the training set. One of the methods used by MATLAB Neural Network Toolbox [ **Ha2014** ] is termed *Early Stopping*. In this method, the given data set is divided into three, namely *Training, Validation & Testing* data-sets which must necessarily be well-correlated for proper results. The training data-set is used solely for training the network. At each iteration, a check is conducted as to how well the network, with current weights and biases, predicts the validation data-set. The simulation is stopped at a point where the error in prediction of training data-set starts to reduce when compared to that of validation data-set. Finally, the testing data-set is used for validating network performance when subjected to a data-set that had no role in training phase.

The input-output data used for training the network is carefully designed to encapsulate the aforementioned three data-sets, with each of them exciting all amplitudes and frequencies in the operating range of the system. As mentioned previously, the dynamic neural network is constructed to predict current system output in terms of delayed inputs and outputs. During the training phase, the previous outputs used by the netweork were the ones simulated by `ode45`. Once the network is trained, the system output predicted by network can be fed back as inputs to the system ( closed-loop network ). The closed-loop preformance of the network is a much more robust metric for checking network performance.

### Network Performance
Once the Neural Net is trained, its performance can be checked by 
> 1. Autocorrelation function, ACF of Error, E = Actual Output, Yact - Predicted Output Ypred.
> 2. Cross-correlation function, CCF of Input, U and Error, E
> 3. Closed-loop performance of Trained Neural Net ( Quantitatively given by Root Mean Square Error, RMSE )

If the **ACF of Error**, E is **not white noise**, OR the **CCF of input, U and Error, E** remains **outside the Confidence Intervals CI**, then it can be understood that further information can be extracted from the data. This is usually done by increasing the number of delayed inputs and outputs that are input ( supplied ) to the network.

## Results
